hydra:
  run:
    dir: "${hydra:runtime.cwd}/cls/${mode}/${quality_level}/${now:%Y-%m-%d_%H-%M-%S}"

root: "${hydra:run.dir}"

mode: "TTT" # pre, TTT, test
model: "tic_svdlora"
dataset: "imagenet"
dataset_path: "${oc.env:HOME}/data/ILSVRC2012/"

gpu_id: 0

num_images: 50000
batch_size: 16
learning_rate: 5.e-3
scheduler: "multistep"
quality_level: 1 # {1,2,3,4}
# VPT_lmbdas: [0.0018, 0.0035, 0.0067, 0.013]
# VPT_lmbdas: [0.0015, 0.0031, 0.0055, 0.011]
VPT_lmbdas: [0.0009, 0.0017, 0.0033, 0.006]
VPT_lmbda: null
LORA_METHOD: "svd" #svd or lora or linear
checkpoint_task: "base_codec" # "base_codec" or "cls"
checkpoint: "${hydra:runtime.cwd}/cls/${quality_level}/checkpoint_best_loss.pth.tar"  # this have to be 'null' when test TransTIC
checkpoint_pre_trained: "${hydra:runtime.cwd}/examples/utils/${checkpoint_task}_{quality_level}.pth.tar"  # 

epochs: 40
num_workers: 4
lmbda:  0.0018 # {0.0018, 0.0035, 0.0067, 0.013}
test_batch_size: 1
aux_learning_rate: 1.e-3
patch_size: 256
cuda: True
save: True
clip_max_norm: 1.0
seed: 42
LOCATION: 'prepend'
DEEP: True
NUM_TOKENS: 16
INITIATION: 'random'
PROJECT: -1
DROPOUT: 0.
TRANSFER_TYPE: 'prompt'
ARCHITECT: 'both'
WINDOW: 'same'
HYPERPRIOR: False
RETURN_ATTENTION: False
MODEL_DECODER: False
MASK_DOWNSAMPLE: 2
DECODER_BLOCK: [1,2,3,4]
hyperparameter_tuning: "False"
